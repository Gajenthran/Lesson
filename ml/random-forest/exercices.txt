1) Avant de commencer à appliquer l'algorithme Random Forest, il faut tout d'abord commencer par importer le package Sklearn et réaliser la commande suivante afin d'importer le module Random Forest: from sklearn.ensemble import RandomForestClassifier.
De plus, pour appliquer notre algorithme Random Forest, il faudra éventuellement un ensemble de données pour pouvoir l'exploiter. C'est pourquoi nous allons nous charger d'importer le contenu du fichier CarteBanquaire.csv. La méthode read_csv du module pandas, fera largement l'affaire pour lire ce fichier.
Dans le cas où nous souhaiterons vérifier notre classifieur, nous séparerons notre base de données en 2 parties: une partie pour l'apprentissage et l'autre pour la phase d'entraînement, à l'aide de train_test_split provenant de sklearn.model_selection. À noter qu'il est important de bien distinguer la colonne "Class" lors de la séparation des données.

2) Un des prétraitement intéressant avant l'utilisation finale du Random Forest, semble être le GridSearchCV. Cet élément là, va nous permettre de pouvoir utiliser les paramètres les plus efficaces pour notre modèle afin d'obtenir les meilleures résultats. Tout d'abord, avant d'utiliser le GridSearchCV, le choix des paramètres pour les tests sont à fixer. Le nombre de paramètres à tester influencera sur le temps d'exécution. Les paramètres qui semblent les plus judicieux pour le GridSearchCV paraissent être "n_estimator", "max_depth", "min_samples_split" et "min_samples_leaf". Nous pourrions en rajouter d'autres, mais cela prendrait trop de temps. 
- {n_estimators} représente le nombre d'arbres de décision dans le modèle. Il a donc un impact important sur la qualité de l'apprentissage des données; en effet, plus la forêt a d'arbres, plus la qualité de l'apprentissage sera importante. Mais cela a aussi un effet sur le temps d'exécution de notre programme qui est un élément à prendre en compte: il est donc essentiel de trouver la bonne valeur pour trouver le juste milieu entre le coût et la performance. 
- {max_depth} représente la profondeur de chaque arbre dans la forêt. Plus l'arbre est profond, plus on aura d'informations à propos des données.
- {min_samples_split} représente le nombre minimal d'échantillons nécessaire pour diviser un noeud interne. Plus cette valeur augmente, plus chaque arbre dans la forêt considérera plus d'échantillons à chaque noeud. Nous avons le choix entre mettre un flottant ou un entier pour cette valeur: si il s'agit d'un entier, cela correspondra au nombre minimum d'échantillons; si il s'agit d'un flottant, cela correspondra au pourcentage d'échantillons.
- {min_samples_leaf} représente le nombre minimal d'échantillons nécessaire pour être au niveau d'un noeud feuille.
param_grid = {
	"n_estimators": [10, 50, 100],
	"max_depth": [5, 8, 15],
	"min_samples_split": [2, 5, 10, 30],
	"min_samples_leaf": [1, 2, 5, 10]
}

Pour traduire ce dictionnaire param_grid, les clés correspondent aux paramètres de Random Forest, et les valeurs sont des tableaux dans lesquelles chaque valeur est une valeur d'un paramètre. Par exemple, nous allons tester, RandomForestClassifier avec le paramètre n_estimators qui prendra les valeurs 10, 50, 100. 
Outre la spécification de l'estimator, en l'occurence ici notre Random Forest, et les paramètres dont nous voulons tester, il existe d'autres paramètres du GridSearchCV que nous pouvons régler.

· Avec le GridSearchCV, nous remarquons que le taux d'erreur de notre meilleur classifieur est de 0.999567 avec les paramètres suivants: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}

· Voici un aperçu de tous les estimators et de leurs taux d'erreurs: [fichier.exo6.txt]

· Comparons maintenant deux estimators, en l'occurence l'estimator le plus performant et le moins performant: 
- le moins performant -> 0.999327 (0.000146) with: {'max_depth': 5, 'min_samples_leaf': 10, 'min_samples_split': 5, 'n_estimators': 10}
- le plus performant ->  0.999567 (0.000109) with: {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}

3) Ainsi notre modèle Random Forest est de 0.999567.

4) Pour récupérer les estimators de notre Random Forest, il faut d'abord connaître la valeur que nous avons attribué à {n_estimator}; en effet, comme nous l'avons vu précédemment {n_estimator} nous indique le nombre d'arbre utilisée pour le modèle, et plus précisément il nous indique le nombre de DecisionTreeClassifier que l'on va utiliser. On peut accéder à chaque arbre avec l'attribut {estimators} de {RandomForestClassifier}, une fois la classification réalisée; cet attribut nous renvoie une liste de DecisionTreeClassifier dont le nombre d'éléments est équivalent à {n_estimator}. Pour savoir lequel des estimators est le plus performants, nous allons tester chacun des estimators avec notre test de données et utiliser une méthode permettant de calculer les taux d'erreur comme MSE (Mean Squared Error), MAE (Mean Absolute Error), RMSE (Root Mean Squared Error)...

5) Voici le taux d'erreur de tous les estimators de notre modèle [fichier.exo5.txt]

6) 
- Le taux d'erreur de l'estimator le plus performant est de 0.0006934508396021874.
- Le taux d'erreur de l'estimator le moins performant  est de 0.0010357873300387104.

7) La différence entre la moyenne des taux d'erreur des deux estimators et le taux d'erreur de notre meilleur modèle Random Forest sont de:
- La moyenne des taux d'erreur des deux estimators: 0.00096117553084100665
- Le taux d'erreur de notre meilleur modèle Random Forest: 
- VAL = 

On remarque grâce à cette valeur, on obtient souvent la même valeur (en répétant cette action plusieurs, nous pouvons plus ou moins arrivé à cette conclusion). Ainsi la différence entre la moyenne des taux d'errreur des deux estimators et le taux d'erreur de notre modèle peut se percevoir sur le fait que le taux d'erreur du modèle correspond plus à une moyenne de l'ensemble des arbres plutôt qu'un de ces deux estimators.

8) 








