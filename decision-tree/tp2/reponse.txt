1 - max_depth permet d'impacter sur la profondeur maximale de l'arbre obtenu. Si on augmente le max_depth, on diminuera le taux d'erreur des tests. A l'inverse, si on diminue le max_depth, on augmentera le taux d'erreur des tests. Mais il faudra également prendre en considération, les problèmes avec le sur-apprentissage avec le max_depth
Quant à min_samples_leaf sert à donner le nombre minimal d'échantillons nécessaires dans un noeud feuille. Cela permettra d'influencer sur la qualité du modèle (avec un modèle plus lisse ou non). Comme nous le voyons dans le second en partageant la base de données pour la phase d'apprentissage, et de test, on remarque l'importance de la profondeur de l'arbre et du choix du nombre minimal d'échantillons nécessaires. On voit l'impact que cela peut avoir si l'on choisit des valeurs trop absurde concernant le max_depth ou le min_samples_leaf comme le phénomène d'overfitting.

2.1 - La paire [1, 2] semble être la paire la plus adéquate car la séparation entre les classes est la plus marquée. Il suffit pour cela de faire l'ensemble des combinaisons possibles sur le tableau "pair" dans le code pour retrouver la meilleur séparation possibe entre les classes, en sachant qu'il y existe 4 attributs (longueur sépale, largeur sépale, longueur pétale et largeur pétale)

3.1 Avec une valeur trop grande, on se retrouve avec un problème de sur apprentissage, c'est-à-dire que le résultat n'est pas un résultat généralisé des données (trop précis). A l'inverse, lorsque la valeur est trop petite, on remarque un sous-apprentissage, car la courbe n'est pas représentatif des données (trop vague). Il faudrait privilégier une valeur faible pour max_depth, pour avoir un semblant de courbe généralisée.